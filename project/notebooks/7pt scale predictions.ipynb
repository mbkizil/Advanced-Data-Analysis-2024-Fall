{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7d626927-500c-4158-afa1-ab9a1a2b025e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Confusion Matrix ===\n",
      "[[405  27]\n",
      " [ 57 205]]\n",
      "\n",
      "=== Classification Report ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.94      0.91       432\n",
      "           1       0.88      0.78      0.83       262\n",
      "\n",
      "    accuracy                           0.88       694\n",
      "   macro avg       0.88      0.86      0.87       694\n",
      "weighted avg       0.88      0.88      0.88       694\n",
      "\n",
      "\n",
      "=== Logistic Regression Coefficients ===\n",
      "         Predictor  Coefficient\n",
      "0  vote2016_binary     2.619750\n",
      "6    20HandleImmig     0.436856\n",
      "5   20HandleHealth     0.311764\n",
      "4         20SocMed     0.098029\n",
      "8        20Liberal     0.014091\n",
      "7       20Feminist     0.008799\n",
      "9            20Blm     0.008110\n",
      "2            20Age     0.003327\n",
      "3         20Income    -0.017408\n",
      "1     20GunHowMany    -0.055867\n",
      "\n",
      "=== With Odds Ratios ===\n",
      "         Predictor  Coefficient  OddsRatio\n",
      "0  vote2016_binary     2.619750  13.732289\n",
      "6    20HandleImmig     0.436856   1.547833\n",
      "5   20HandleHealth     0.311764   1.365833\n",
      "4         20SocMed     0.098029   1.102995\n",
      "8        20Liberal     0.014091   1.014191\n",
      "7       20Feminist     0.008799   1.008838\n",
      "9            20Blm     0.008110   1.008143\n",
      "2            20Age     0.003327   1.003332\n",
      "3         20Income    -0.017408   0.982743\n",
      "1     20GunHowMany    -0.055867   0.945665\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# ----------------------------------------------------------------\n",
    "# 1. Load data (assume 'df' is already loaded in memory)\n",
    "# ----------------------------------------------------------------\n",
    "\n",
    "# Example: If you have a CSV, you'd do:\n",
    "df = pd.read_csv(\"vote_gun_demo_opinions.csv\")\n",
    "\n",
    "# ----------------------------------------------------------------\n",
    "# 2. Create a binary outcome for 2020 Vote\n",
    "#    For instance, let's define:\n",
    "#    1 if 20Vote == \"Democrat\"\n",
    "#    0 otherwise (Republican, Independent, Other, No answer, etc.)\n",
    "# ----------------------------------------------------------------\n",
    "def make_binary_vote(v):\n",
    "    return 1 if v == \"Democrat\" else 0\n",
    "\n",
    "df[\"vote2020_binary\"] = df[\"20Vote\"].apply(make_binary_vote)\n",
    "\n",
    "# ----------------------------------------------------------------\n",
    "# 3. Define a variable for 2016 voting behavior (predictor)\n",
    "#    Similarly, we can do a simple binary: 1 if 'Democrat', else 0\n",
    "# ----------------------------------------------------------------\n",
    "def make_binary_vote_16(v):\n",
    "    return 1 if v == \"Democrat\" else 0\n",
    "\n",
    "df[\"vote2016_binary\"] = df[\"16Vote\"].apply(make_binary_vote_16)\n",
    "\n",
    "# ----------------------------------------------------------------\n",
    "# 4. Select your 2020 features\n",
    "#    For illustration, let's pick some numeric columns from 2020.\n",
    "#    You can expand or refine this list as you wish.\n",
    "# ----------------------------------------------------------------\n",
    "predictor_cols_20 = [\n",
    "    #\"20GunHarder\",       # numeric or recoded \n",
    "    #\"20GunImportance\",   # numeric or recoded\n",
    "    \"20GunHowMany\",      # numeric\n",
    "    \"20Age\",             # numeric\n",
    "    \"20Income\",          # numeric\n",
    "    \"20SocMed\",          # numeric\n",
    "    \"20HandleHealth\",    # numeric\n",
    "    \"20HandleImmig\",     # numeric\n",
    "    \"20Feminist\",        # numeric (0-100 scale)\n",
    "    \"20Liberal\",         # numeric (0-100 scale)\n",
    "    \"20Blm\",             # numeric (0-100 scale)\n",
    "    # ... add more if relevant\n",
    "]\n",
    "\n",
    "# ----------------------------------------------------------------\n",
    "# 5. Combine 2016 voting behavior + the selected 2020 features\n",
    "# ----------------------------------------------------------------\n",
    "predictors = [\"vote2016_binary\"] + predictor_cols_20\n",
    "\n",
    "# ----------------------------------------------------------------\n",
    "# 6. Drop rows with missing data in any of these columns or outcome\n",
    "# ----------------------------------------------------------------\n",
    "model_data = df.dropna(subset=predictors + [\"vote2020_binary\"]).copy()\n",
    "\n",
    "# ----------------------------------------------------------------\n",
    "# 7. Create X, y\n",
    "# ----------------------------------------------------------------\n",
    "X = model_data[predictors]\n",
    "y = model_data[\"vote2020_binary\"]\n",
    "\n",
    "# ----------------------------------------------------------------\n",
    "# 8. Train-test split (or cross-validation)\n",
    "# ----------------------------------------------------------------\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# ----------------------------------------------------------------\n",
    "# 9. Fit Logistic Regression\n",
    "#    We can use some regularization (C=1.0 default).\n",
    "#    If you want to see coefficients more easily, \n",
    "#    you might turn off penalty or pick a larger C. \n",
    "# ----------------------------------------------------------------\n",
    "model = LogisticRegression(\n",
    "  # no regularization (use carefully)\n",
    "    solver=\"lbfgs\",\n",
    "    max_iter=1000\n",
    ")\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# ----------------------------------------------------------------\n",
    "# 10. Evaluate\n",
    "# ----------------------------------------------------------------\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print(\"=== Confusion Matrix ===\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "print(\"\\n=== Classification Report ===\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# ----------------------------------------------------------------\n",
    "# 11. Look at Coefficients\n",
    "# ----------------------------------------------------------------\n",
    "# The model has a single set of coefficients for each predictor\n",
    "coeffs = pd.DataFrame({\n",
    "    \"Predictor\": X.columns,\n",
    "    \"Coefficient\": model.coef_[0]\n",
    "}).sort_values(by=\"Coefficient\", ascending=False)\n",
    "\n",
    "print(\"\\n=== Logistic Regression Coefficients ===\")\n",
    "print(coeffs)\n",
    "\n",
    "# If you'd like to interpret them as odds ratios:\n",
    "coeffs[\"OddsRatio\"] = np.exp(coeffs[\"Coefficient\"])\n",
    "print(\"\\n=== With Odds Ratios ===\")\n",
    "print(coeffs)\n",
    "\n",
    "# You might find interesting which variables have the largest positive\n",
    "# or negative effect on the probability of voting Democrat (in 2020)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed0a4971-33b3-4e65-b220-45dfd286cad4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "aa5d6418-8474-4b22-a0ea-c866a3511fba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>16GunHowMany</th>\n",
       "      <th>20GunHowMany</th>\n",
       "      <th>16Age</th>\n",
       "      <th>20Age</th>\n",
       "      <th>16Income</th>\n",
       "      <th>20Income</th>\n",
       "      <th>16Marriage</th>\n",
       "      <th>20Marriage</th>\n",
       "      <th>16SocMed</th>\n",
       "      <th>20SocMed</th>\n",
       "      <th>...</th>\n",
       "      <th>20Conservatives</th>\n",
       "      <th>20Gay</th>\n",
       "      <th>20Congress</th>\n",
       "      <th>20Muslims</th>\n",
       "      <th>20Jews</th>\n",
       "      <th>20Christ</th>\n",
       "      <th>20Police</th>\n",
       "      <th>20Transgender</th>\n",
       "      <th>20Scientist</th>\n",
       "      <th>20Blm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2686.000000</td>\n",
       "      <td>2624.000000</td>\n",
       "      <td>2759.000000</td>\n",
       "      <td>2747.000000</td>\n",
       "      <td>2724.000000</td>\n",
       "      <td>2661.000000</td>\n",
       "      <td>2822.000000</td>\n",
       "      <td>2826.000000</td>\n",
       "      <td>2834.000000</td>\n",
       "      <td>2652.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>2619.000000</td>\n",
       "      <td>2630.000000</td>\n",
       "      <td>2644.000000</td>\n",
       "      <td>2624.000000</td>\n",
       "      <td>2623.000000</td>\n",
       "      <td>2638.000000</td>\n",
       "      <td>2650.000000</td>\n",
       "      <td>2626.000000</td>\n",
       "      <td>2645.000000</td>\n",
       "      <td>2637.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.432986</td>\n",
       "      <td>1.548399</td>\n",
       "      <td>49.455962</td>\n",
       "      <td>52.859847</td>\n",
       "      <td>16.157122</td>\n",
       "      <td>11.993611</td>\n",
       "      <td>2.874557</td>\n",
       "      <td>2.722222</td>\n",
       "      <td>2.190896</td>\n",
       "      <td>2.147436</td>\n",
       "      <td>...</td>\n",
       "      <td>54.787323</td>\n",
       "      <td>64.900000</td>\n",
       "      <td>44.213691</td>\n",
       "      <td>57.616616</td>\n",
       "      <td>72.822722</td>\n",
       "      <td>72.024640</td>\n",
       "      <td>71.772075</td>\n",
       "      <td>58.744478</td>\n",
       "      <td>78.875236</td>\n",
       "      <td>51.380736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>4.170547</td>\n",
       "      <td>5.312135</td>\n",
       "      <td>17.034521</td>\n",
       "      <td>16.566437</td>\n",
       "      <td>7.847302</td>\n",
       "      <td>6.635598</td>\n",
       "      <td>2.116728</td>\n",
       "      <td>2.053527</td>\n",
       "      <td>0.805848</td>\n",
       "      <td>0.813724</td>\n",
       "      <td>...</td>\n",
       "      <td>28.225116</td>\n",
       "      <td>26.343841</td>\n",
       "      <td>21.820635</td>\n",
       "      <td>24.295803</td>\n",
       "      <td>21.864978</td>\n",
       "      <td>24.799181</td>\n",
       "      <td>24.478697</td>\n",
       "      <td>27.146190</td>\n",
       "      <td>20.098893</td>\n",
       "      <td>35.409933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>39.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>15.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>54.000000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>75.000000</td>\n",
       "      <td>75.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>85.000000</td>\n",
       "      <td>60.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>63.000000</td>\n",
       "      <td>67.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>85.000000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>90.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>88.750000</td>\n",
       "      <td>85.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>85.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>99.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>90.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 44 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       16GunHowMany  20GunHowMany        16Age        20Age     16Income  \\\n",
       "count   2686.000000   2624.000000  2759.000000  2747.000000  2724.000000   \n",
       "mean       1.432986      1.548399    49.455962    52.859847    16.157122   \n",
       "std        4.170547      5.312135    17.034521    16.566437     7.847302   \n",
       "min        0.000000      0.000000    18.000000    19.000000     1.000000   \n",
       "25%        0.000000      0.000000    35.000000    39.000000    11.000000   \n",
       "50%        0.000000      0.000000    50.000000    54.000000    17.000000   \n",
       "75%        1.000000      1.000000    63.000000    67.000000    23.000000   \n",
       "max       99.000000     99.000000    90.000000    80.000000    28.000000   \n",
       "\n",
       "          20Income   16Marriage   20Marriage     16SocMed     20SocMed  ...  \\\n",
       "count  2661.000000  2822.000000  2826.000000  2834.000000  2652.000000  ...   \n",
       "mean     11.993611     2.874557     2.722222     2.190896     2.147436  ...   \n",
       "std       6.635598     2.116728     2.053527     0.805848     0.813724  ...   \n",
       "min       1.000000     1.000000     1.000000     1.000000     1.000000  ...   \n",
       "25%       6.000000     1.000000     1.000000     2.000000     2.000000  ...   \n",
       "50%      12.000000     1.000000     1.000000     2.000000     2.000000  ...   \n",
       "75%      18.000000     5.000000     4.000000     3.000000     3.000000  ...   \n",
       "max      22.000000     6.000000     6.000000     4.000000     4.000000  ...   \n",
       "\n",
       "       20Conservatives        20Gay   20Congress    20Muslims       20Jews  \\\n",
       "count      2619.000000  2630.000000  2644.000000  2624.000000  2623.000000   \n",
       "mean         54.787323    64.900000    44.213691    57.616616    72.822722   \n",
       "std          28.225116    26.343841    21.820635    24.295803    21.864978   \n",
       "min           0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%          40.000000    50.000000    30.000000    50.000000    50.000000   \n",
       "50%          50.000000    60.000000    50.000000    50.000000    70.000000   \n",
       "75%          80.000000    85.000000    60.000000    70.000000    90.000000   \n",
       "max         100.000000   100.000000   100.000000   100.000000   100.000000   \n",
       "\n",
       "          20Christ     20Police  20Transgender  20Scientist        20Blm  \n",
       "count  2638.000000  2650.000000    2626.000000  2645.000000  2637.000000  \n",
       "mean     72.024640    71.772075      58.744478    78.875236    51.380736  \n",
       "std      24.799181    24.478697      27.146190    20.098893    35.409933  \n",
       "min       0.000000     0.000000       0.000000     0.000000     0.000000  \n",
       "25%      50.000000    60.000000      50.000000    70.000000    15.000000  \n",
       "50%      75.000000    75.000000      50.000000    85.000000    60.000000  \n",
       "75%     100.000000    88.750000      85.000000   100.000000    85.000000  \n",
       "max     100.000000   100.000000     100.000000   100.000000   100.000000  \n",
       "\n",
       "[8 rows x 44 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "5159cd5d-a62a-406a-874d-8389a797a622",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "df121e43-0619-4563-8908-be6c5582ebb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"vote_gun_demo_opinions.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "7b7096d0-3c57-4639-9a4a-a7d1e558935a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                Strong Republican\n",
       "1       Not very strong Republican\n",
       "2           Independent-Republican\n",
       "3             Independent-Democrat\n",
       "4                  Strong Democrat\n",
       "                   ...            \n",
       "2834             Strong Republican\n",
       "2835               Strong Democrat\n",
       "2836      Not very strong Democrat\n",
       "2837               Strong Democrat\n",
       "2838               Strong Democrat\n",
       "Name: 16VoteSum, Length: 2839, dtype: object"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "3dbfdfd4-c459-40a3-a774-da958d21b558",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       7.0\n",
      "1       4.0\n",
      "2       5.0\n",
      "3       4.0\n",
      "4       1.0\n",
      "       ... \n",
      "2834    1.0\n",
      "2835    1.0\n",
      "2836    1.0\n",
      "2837    2.0\n",
      "2838    7.0\n",
      "Name: 20VoteSum, Length: 2839, dtype: float64\n",
      "=== Confusion Matrix ===\n",
      "[[102   5   7   5   1   0   0]\n",
      " [ 21  14   4   8   0   3   0]\n",
      " [ 23   2  20   4   2   0   0]\n",
      " [  5   3  11   9   6   7   3]\n",
      " [  3   0   2   4   9   3  22]\n",
      " [  2   0   0   4   7   7  23]\n",
      " [  0   1   0   4   4   4  83]]\n",
      "\n",
      "=== Classification Report ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.65      0.85      0.74       120\n",
      "         2.0       0.56      0.28      0.37        50\n",
      "         3.0       0.45      0.39      0.42        51\n",
      "         4.0       0.24      0.20      0.22        44\n",
      "         5.0       0.31      0.21      0.25        43\n",
      "         6.0       0.29      0.16      0.21        43\n",
      "         7.0       0.63      0.86      0.73        96\n",
      "\n",
      "    accuracy                           0.55       447\n",
      "   macro avg       0.45      0.42      0.42       447\n",
      "weighted avg       0.51      0.55      0.51       447\n",
      "\n",
      "\n",
      "=== Multinomial Regression Coefficients ===\n",
      "\n",
      "Class '1.0' vs. others:\n",
      "  Intercept: -0.7316702422549523\n",
      "  20HandleHealth: 0.5468\n",
      "  20GunHowMany: -0.1484\n",
      "  20HandleImmig: 0.5314\n",
      "  20SocMed: -0.0650\n",
      "  20Age: 0.1166\n",
      "  20Fundamentalist: 0.0772\n",
      "  20Feminist: 0.1698\n",
      "  20Liberal: 0.5349\n",
      "  20Union: 0.1087\n",
      "  20BigBusiness: 0.0177\n",
      "  20Conservatives: -0.6848\n",
      "  20Gay: 0.2006\n",
      "  20Congress: 0.2902\n",
      "  20Muslims: 0.0620\n",
      "  20Jews: 0.0526\n",
      "  20Christ: 0.1314\n",
      "  20Police: -0.0490\n",
      "  20Transgender: -0.2289\n",
      "  20Scientist: 0.1061\n",
      "  20Blm: 0.5286\n",
      "  16VoteSum: -2.4404\n",
      "\n",
      "Class '2.0' vs. others:\n",
      "  Intercept: 0.28014108034690965\n",
      "  20HandleHealth: 0.4559\n",
      "  20GunHowMany: -0.1988\n",
      "  20HandleImmig: 0.2027\n",
      "  20SocMed: 0.3309\n",
      "  20Age: -0.2036\n",
      "  20Fundamentalist: 0.0302\n",
      "  20Feminist: 0.1678\n",
      "  20Liberal: 0.2314\n",
      "  20Union: 0.0110\n",
      "  20BigBusiness: 0.0218\n",
      "  20Conservatives: -0.5580\n",
      "  20Gay: 0.2694\n",
      "  20Congress: 0.0974\n",
      "  20Muslims: 0.1238\n",
      "  20Jews: -0.0092\n",
      "  20Christ: 0.0667\n",
      "  20Police: -0.0228\n",
      "  20Transgender: -0.0776\n",
      "  20Scientist: -0.0376\n",
      "  20Blm: -0.0091\n",
      "  16VoteSum: -1.1833\n",
      "\n",
      "Class '3.0' vs. others:\n",
      "  Intercept: 0.13625034200334768\n",
      "  20HandleHealth: 0.6518\n",
      "  20GunHowMany: 0.1116\n",
      "  20HandleImmig: 0.2594\n",
      "  20SocMed: 0.1766\n",
      "  20Age: -0.1012\n",
      "  20Fundamentalist: -0.2188\n",
      "  20Feminist: 0.0487\n",
      "  20Liberal: 0.4159\n",
      "  20Union: 0.1337\n",
      "  20BigBusiness: 0.0437\n",
      "  20Conservatives: -0.5393\n",
      "  20Gay: -0.0051\n",
      "  20Congress: -0.1337\n",
      "  20Muslims: 0.0330\n",
      "  20Jews: 0.0329\n",
      "  20Christ: -0.0134\n",
      "  20Police: -0.1135\n",
      "  20Transgender: -0.0469\n",
      "  20Scientist: 0.2396\n",
      "  20Blm: 0.3738\n",
      "  16VoteSum: -0.4344\n",
      "\n",
      "Class '4.0' vs. others:\n",
      "  Intercept: 0.9890203920715519\n",
      "  20HandleHealth: 0.1988\n",
      "  20GunHowMany: -0.0608\n",
      "  20HandleImmig: -0.0764\n",
      "  20SocMed: 0.0992\n",
      "  20Age: -0.0816\n",
      "  20Fundamentalist: 0.0683\n",
      "  20Feminist: 0.0016\n",
      "  20Liberal: -0.0896\n",
      "  20Union: -0.0582\n",
      "  20BigBusiness: -0.0095\n",
      "  20Conservatives: 0.2506\n",
      "  20Gay: -0.3485\n",
      "  20Congress: -0.2124\n",
      "  20Muslims: 0.0885\n",
      "  20Jews: -0.0168\n",
      "  20Christ: -0.1909\n",
      "  20Police: -0.1393\n",
      "  20Transgender: 0.3239\n",
      "  20Scientist: -0.0815\n",
      "  20Blm: -0.1458\n",
      "  16VoteSum: 0.0955\n",
      "\n",
      "Class '5.0' vs. others:\n",
      "  Intercept: 0.36691134577833046\n",
      "  20HandleHealth: -0.5573\n",
      "  20GunHowMany: 0.0731\n",
      "  20HandleImmig: -0.1080\n",
      "  20SocMed: -0.2991\n",
      "  20Age: 0.1746\n",
      "  20Fundamentalist: 0.0474\n",
      "  20Feminist: -0.1749\n",
      "  20Liberal: -0.2699\n",
      "  20Union: 0.0483\n",
      "  20BigBusiness: -0.0116\n",
      "  20Conservatives: 0.5829\n",
      "  20Gay: -0.0721\n",
      "  20Congress: -0.2521\n",
      "  20Muslims: -0.0598\n",
      "  20Jews: 0.0395\n",
      "  20Christ: -0.0668\n",
      "  20Police: -0.0945\n",
      "  20Transgender: -0.0093\n",
      "  20Scientist: -0.1285\n",
      "  20Blm: -0.1895\n",
      "  16VoteSum: 0.7770\n",
      "\n",
      "Class '6.0' vs. others:\n",
      "  Intercept: 0.26721056196333265\n",
      "  20HandleHealth: -0.3182\n",
      "  20GunHowMany: 0.0724\n",
      "  20HandleImmig: -0.2063\n",
      "  20SocMed: -0.0007\n",
      "  20Age: -0.0404\n",
      "  20Fundamentalist: -0.0400\n",
      "  20Feminist: -0.0382\n",
      "  20Liberal: -0.2981\n",
      "  20Union: -0.1808\n",
      "  20BigBusiness: -0.0526\n",
      "  20Conservatives: 0.3776\n",
      "  20Gay: -0.0424\n",
      "  20Congress: 0.0554\n",
      "  20Muslims: 0.0380\n",
      "  20Jews: -0.1221\n",
      "  20Christ: 0.0381\n",
      "  20Police: 0.1807\n",
      "  20Transgender: 0.0370\n",
      "  20Scientist: -0.0397\n",
      "  20Blm: -0.1848\n",
      "  16VoteSum: 1.1757\n",
      "\n",
      "Class '7.0' vs. others:\n",
      "  Intercept: -1.3078634799085345\n",
      "  20HandleHealth: -0.9779\n",
      "  20GunHowMany: 0.1510\n",
      "  20HandleImmig: -0.6028\n",
      "  20SocMed: -0.2419\n",
      "  20Age: 0.1356\n",
      "  20Fundamentalist: 0.0356\n",
      "  20Feminist: -0.1748\n",
      "  20Liberal: -0.5248\n",
      "  20Union: -0.0626\n",
      "  20BigBusiness: -0.0094\n",
      "  20Conservatives: 0.5711\n",
      "  20Gay: -0.0019\n",
      "  20Congress: 0.1553\n",
      "  20Muslims: -0.2855\n",
      "  20Jews: 0.0232\n",
      "  20Christ: 0.0349\n",
      "  20Police: 0.2384\n",
      "  20Transgender: 0.0019\n",
      "  20Scientist: -0.0584\n",
      "  20Blm: -0.3732\n",
      "  16VoteSum: 2.0098\n",
      "\n",
      "Mean Ordinal Error (0=perfect): 0.79\n",
      "Mean Squared Ordinal Error: 1.70\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "# 1) Read the CSV file\n",
    "df = pd.read_csv(\"vote_gun_demo_opinions.csv\")\n",
    "\n",
    "# --------------------------------------------------------------\n",
    "# 2) Prepare columns: define your 2020 numeric features + 16VoteSum\n",
    "#    Adjust this list to match your actual numeric 2020 columns\n",
    "# --------------------------------------------------------------\n",
    "twenty_features = ['20HandleHealth',  '20GunHowMany','20HandleImmig','20SocMed', '20Age',\n",
    "'20Fundamentalist', '20Feminist', '20Liberal',\n",
    "       '20Union', '20BigBusiness', '20Conservatives', '20Gay', '20Congress',\n",
    "       '20Muslims', '20Jews', '20Christ', '20Police', '20Transgender',\n",
    "       '20Scientist', '20Blm']\n",
    "\n",
    "\n",
    "# We'll include 16VoteSum as part of our predictors\n",
    "predictors = twenty_features + [\"16VoteSum\"]\n",
    "\n",
    "# --------------------------------------------------------------\n",
    "# 3) Ensure 16VoteSum and 20VoteSum are numeric\n",
    "# --------------------------------------------------------------\n",
    "mapping_16 = {\n",
    "    \"Strong Democrat\": 1,\n",
    "    \"Not very strong Democrat\": 2,\n",
    "    \"Independent-Democrat\": 3,\n",
    "    \"Independent\": 4,\n",
    "    \"Independent-Republican\": 5,\n",
    "    \"Not very strong Republican\": 6,\n",
    "    \"Strong Republican\": 7\n",
    "}\n",
    "\n",
    "# For 2016\n",
    "df[\"16VoteSum\"] = df[\"16VoteSum\"].map(mapping_16)\n",
    "df[\"20VoteSum\"] = df[\"20VoteSum\"].map(mapping_16)\n",
    "print(df[\"20VoteSum\"])\n",
    "\n",
    "# --------------------------------------------------------------\n",
    "# 4) Drop rows where any needed column is missing\n",
    "# --------------------------------------------------------------\n",
    "df_clean = df.dropna(subset=predictors + [\"20VoteSum\"]).copy()\n",
    "\n",
    "# --------------------------------------------------------------\n",
    "# 5) Create X (predictors) and y (target)\n",
    "# --------------------------------------------------------------\n",
    "X = df_clean[predictors]\n",
    "y = df_clean[\"20VoteSum\"]  # This is multiclass (1..7, for example)\n",
    "\n",
    "# --------------------------------------------------------------\n",
    "# 6) Train/Test Split\n",
    "# --------------------------------------------------------------\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=y  # helps preserve class proportions\n",
    ")\n",
    "\n",
    "# --------------------------------------------------------------\n",
    "# 7) (Optional) Scale numeric features to help with convergence\n",
    "# --------------------------------------------------------------\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled  = scaler.transform(X_test)\n",
    "\n",
    "# --------------------------------------------------------------\n",
    "# 8) Multinomial Logistic Regression\n",
    "#    We'll use solver='lbfgs' which supports multi_class='multinomial'\n",
    "# --------------------------------------------------------------\n",
    "model = LogisticRegression(\n",
    "    multi_class='multinomial',\n",
    "    solver='lbfgs',\n",
    "    penalty='l2',\n",
    "    C=1.0,         # inverse of regularization strength\n",
    "    max_iter=500,  # increase if you see convergence warnings\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# --------------------------------------------------------------\n",
    "# 9) Evaluate Predictions\n",
    "# --------------------------------------------------------------\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "print(\"=== Confusion Matrix ===\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "print(\"\\n=== Classification Report ===\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# --------------------------------------------------------------\n",
    "# 10) Look at Coefficients\n",
    "#     model.coef_ is shape [n_classes, n_features]\n",
    "# --------------------------------------------------------------\n",
    "classes_ = model.classes_  # e.g., array([1,2,3,4,5,6,7]) if those are the labels\n",
    "coefs = model.coef_\n",
    "intercepts = model.intercept_\n",
    "\n",
    "print(\"\\n=== Multinomial Regression Coefficients ===\")\n",
    "for i, cls in enumerate(classes_):\n",
    "    print(f\"\\nClass '{cls}' vs. others:\")\n",
    "    print(\"  Intercept:\", intercepts[i])\n",
    "    for j, col in enumerate(predictors):\n",
    "        print(f\"  {col}: {coefs[i][j]:.4f}\")\n",
    "\n",
    "# --------------------------------------------------------------\n",
    "# 11) (Optional) Calculate an Ordinal Metric\n",
    "#     e.g., the average absolute difference |y_pred - y_true|\n",
    "# --------------------------------------------------------------\n",
    "def mean_ordinal_error(y_true, y_pred):\n",
    "    # Both are numeric arrays (e.g., 1..7)\n",
    "    return np.mean(np.abs(y_true - y_pred))\n",
    "\n",
    "moe = mean_ordinal_error(y_test, y_pred)\n",
    "print(f\"\\nMean Ordinal Error (0=perfect): {moe:.2f}\")\n",
    "\n",
    "# Another approach: Weighted MSE\n",
    "def mean_squared_ordinal_error(y_true, y_pred):\n",
    "    return np.mean((y_true - y_pred)**2)\n",
    "\n",
    "mse = mean_squared_ordinal_error(y_test, y_pred)\n",
    "print(f\"Mean Squared Ordinal Error: {mse:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77429d2d-0485-4b62-9309-718f038b1345",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e841335e-a1a6-4c53-b4d8-725bcfdd1bf7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "13a5e774-7f19-4bbc-bd55-80b54038bd7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Confusion Matrix ===\n",
      "[[95  8  5  6  1  1  5]\n",
      " [26 10  4  6  0  4  0]\n",
      " [34  4  7  4  1  1  0]\n",
      " [10  7  5 10  0  6  7]\n",
      " [ 5  2  0  2  6  3 25]\n",
      " [ 2  3  1  4  4  4 25]\n",
      " [ 0  0  2  3  3  4 84]]\n",
      "\n",
      "=== Classification Report ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.55      0.79      0.65       121\n",
      "         2.0       0.29      0.20      0.24        50\n",
      "         3.0       0.29      0.14      0.19        51\n",
      "         4.0       0.29      0.22      0.25        45\n",
      "         5.0       0.40      0.14      0.21        43\n",
      "         6.0       0.17      0.09      0.12        43\n",
      "         7.0       0.58      0.88      0.69        96\n",
      "\n",
      "    accuracy                           0.48       449\n",
      "   macro avg       0.37      0.35      0.34       449\n",
      "weighted avg       0.42      0.48      0.43       449\n",
      "\n",
      "\n",
      "=== Multinomial Regression Coefficients ===\n",
      "\n",
      "Class '1.0' vs. others:\n",
      "  Intercept: -0.23435662099650925\n",
      "  20HandleHealth: 0.8213\n",
      "  20GunHowMany: -0.1603\n",
      "  20HandleImmig: 0.5949\n",
      "  20SocMed: -0.2020\n",
      "  20Age: 0.2284\n",
      "  20Fundamentalist: 0.1826\n",
      "  20Feminist: 0.2430\n",
      "  20Liberal: 0.8018\n",
      "  20Union: 0.3092\n",
      "  20BigBusiness: -0.0882\n",
      "  20Conservatives: -0.7933\n",
      "  20Gay: 0.0271\n",
      "  20Congress: 0.2058\n",
      "  20Muslims: 0.0060\n",
      "  20Jews: -0.1284\n",
      "  20Christ: 0.1848\n",
      "  20Police: -0.2072\n",
      "  20Transgender: -0.2299\n",
      "  20Scientist: 0.0942\n",
      "  20Blm: 0.5344\n",
      "\n",
      "Class '2.0' vs. others:\n",
      "  Intercept: 0.15553578636880408\n",
      "  20HandleHealth: 0.4489\n",
      "  20GunHowMany: -0.1431\n",
      "  20HandleImmig: 0.2253\n",
      "  20SocMed: 0.2661\n",
      "  20Age: -0.1475\n",
      "  20Fundamentalist: 0.0809\n",
      "  20Feminist: 0.1621\n",
      "  20Liberal: 0.3317\n",
      "  20Union: 0.1359\n",
      "  20BigBusiness: -0.0650\n",
      "  20Conservatives: -0.5843\n",
      "  20Gay: 0.1604\n",
      "  20Congress: 0.0448\n",
      "  20Muslims: 0.0339\n",
      "  20Jews: -0.1171\n",
      "  20Christ: 0.0989\n",
      "  20Police: -0.0697\n",
      "  20Transgender: -0.0010\n",
      "  20Scientist: -0.0836\n",
      "  20Blm: 0.0533\n",
      "\n",
      "Class '3.0' vs. others:\n",
      "  Intercept: -0.17190803258570958\n",
      "  20HandleHealth: 0.5380\n",
      "  20GunHowMany: 0.2038\n",
      "  20HandleImmig: 0.3460\n",
      "  20SocMed: 0.0367\n",
      "  20Age: -0.1212\n",
      "  20Fundamentalist: -0.1627\n",
      "  20Feminist: 0.0666\n",
      "  20Liberal: 0.4125\n",
      "  20Union: 0.2204\n",
      "  20BigBusiness: -0.1059\n",
      "  20Conservatives: -0.4384\n",
      "  20Gay: -0.0845\n",
      "  20Congress: -0.1040\n",
      "  20Muslims: -0.1014\n",
      "  20Jews: -0.0635\n",
      "  20Christ: 0.0991\n",
      "  20Police: -0.1862\n",
      "  20Transgender: 0.0920\n",
      "  20Scientist: 0.2717\n",
      "  20Blm: 0.3350\n",
      "\n",
      "Class '4.0' vs. others:\n",
      "  Intercept: 0.621847017000827\n",
      "  20HandleHealth: 0.1120\n",
      "  20GunHowMany: 0.0432\n",
      "  20HandleImmig: -0.0739\n",
      "  20SocMed: 0.1101\n",
      "  20Age: -0.0635\n",
      "  20Fundamentalist: 0.0560\n",
      "  20Feminist: 0.0178\n",
      "  20Liberal: -0.1842\n",
      "  20Union: 0.0390\n",
      "  20BigBusiness: 0.0179\n",
      "  20Conservatives: 0.1039\n",
      "  20Gay: -0.1538\n",
      "  20Congress: -0.1742\n",
      "  20Muslims: 0.0386\n",
      "  20Jews: -0.0365\n",
      "  20Christ: -0.1400\n",
      "  20Police: -0.1759\n",
      "  20Transgender: 0.3152\n",
      "  20Scientist: -0.0774\n",
      "  20Blm: -0.2538\n",
      "\n",
      "Class '5.0' vs. others:\n",
      "  Intercept: 0.15782609527373032\n",
      "  20HandleHealth: -0.6440\n",
      "  20GunHowMany: 0.0241\n",
      "  20HandleImmig: -0.1578\n",
      "  20SocMed: -0.2153\n",
      "  20Age: 0.1227\n",
      "  20Fundamentalist: -0.0644\n",
      "  20Feminist: -0.1844\n",
      "  20Liberal: -0.3292\n",
      "  20Union: -0.1084\n",
      "  20BigBusiness: 0.0710\n",
      "  20Conservatives: 0.6098\n",
      "  20Gay: -0.0181\n",
      "  20Congress: -0.2128\n",
      "  20Muslims: 0.0354\n",
      "  20Jews: 0.1180\n",
      "  20Christ: -0.2040\n",
      "  20Police: -0.0204\n",
      "  20Transgender: -0.0307\n",
      "  20Scientist: -0.0091\n",
      "  20Blm: -0.1941\n",
      "\n",
      "Class '6.0' vs. others:\n",
      "  Intercept: 0.2652299834602844\n",
      "  20HandleHealth: -0.3548\n",
      "  20GunHowMany: -0.0043\n",
      "  20HandleImmig: -0.2040\n",
      "  20SocMed: 0.1090\n",
      "  20Age: -0.0324\n",
      "  20Fundamentalist: -0.1076\n",
      "  20Feminist: -0.1078\n",
      "  20Liberal: -0.4026\n",
      "  20Union: -0.3024\n",
      "  20BigBusiness: -0.0181\n",
      "  20Conservatives: 0.3240\n",
      "  20Gay: 0.0658\n",
      "  20Congress: 0.1036\n",
      "  20Muslims: 0.1124\n",
      "  20Jews: 0.0977\n",
      "  20Christ: -0.0034\n",
      "  20Police: 0.2425\n",
      "  20Transgender: -0.0485\n",
      "  20Scientist: -0.0929\n",
      "  20Blm: -0.2292\n",
      "\n",
      "Class '7.0' vs. others:\n",
      "  Intercept: -0.7941742285214208\n",
      "  20HandleHealth: -0.9215\n",
      "  20GunHowMany: 0.0367\n",
      "  20HandleImmig: -0.7304\n",
      "  20SocMed: -0.1046\n",
      "  20Age: 0.0136\n",
      "  20Fundamentalist: 0.0153\n",
      "  20Feminist: -0.1974\n",
      "  20Liberal: -0.6300\n",
      "  20Union: -0.2936\n",
      "  20BigBusiness: 0.1883\n",
      "  20Conservatives: 0.7784\n",
      "  20Gay: 0.0031\n",
      "  20Congress: 0.1369\n",
      "  20Muslims: -0.1249\n",
      "  20Jews: 0.1298\n",
      "  20Christ: -0.0355\n",
      "  20Police: 0.4169\n",
      "  20Transgender: -0.0972\n",
      "  20Scientist: -0.1029\n",
      "  20Blm: -0.2455\n",
      "\n",
      "Mean Ordinal Error (0=perfect): 1.04\n",
      "Mean Squared Ordinal Error: 2.71\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "# 1) Read the CSV file\n",
    "df = pd.read_csv(\"vote_gun_demo_opinions.csv\")\n",
    "\n",
    "# --------------------------------------------------------------\n",
    "# 2) Prepare columns: define your 2020 numeric features + 16VoteSum\n",
    "#    Adjust this list to match your actual numeric 2020 columns\n",
    "# --------------------------------------------------------------\n",
    "twenty_features = ['20HandleHealth',  '20GunHowMany','20HandleImmig','20SocMed', '20Age',\n",
    "'20Fundamentalist', '20Feminist', '20Liberal',\n",
    "       '20Union', '20BigBusiness', '20Conservatives', '20Gay', '20Congress',\n",
    "       '20Muslims', '20Jews', '20Christ', '20Police', '20Transgender',\n",
    "       '20Scientist', '20Blm']\n",
    "\n",
    "\n",
    "# We'll include 16VoteSum as part of our predictors\n",
    "predictors = twenty_features \n",
    "\n",
    "# --------------------------------------------------------------\n",
    "# 3) Ensure 16VoteSum and 20VoteSum are numeric\n",
    "# --------------------------------------------------------------\n",
    "mapping_16 = {\n",
    "    \"Strong Democrat\": 1,\n",
    "    \"Not very strong Democrat\": 2,\n",
    "    \"Independent-Democrat\": 3,\n",
    "    \"Independent\": 4,\n",
    "    \"Independent-Republican\": 5,\n",
    "    \"Not very strong Republican\": 6,\n",
    "    \"Strong Republican\": 7\n",
    "}\n",
    "\n",
    "# For 2016\n",
    "df[\"20VoteSum\"] = df[\"20VoteSum\"].map(mapping_16)\n",
    "\n",
    "# --------------------------------------------------------------\n",
    "# 4) Drop rows where any needed column is missing\n",
    "# --------------------------------------------------------------\n",
    "df_clean = df.dropna(subset=predictors + [\"20VoteSum\"]).copy()\n",
    "\n",
    "# --------------------------------------------------------------\n",
    "# 5) Create X (predictors) and y (target)\n",
    "# --------------------------------------------------------------\n",
    "X = df_clean[predictors]\n",
    "y = df_clean[\"20VoteSum\"]  # This is multiclass (1..7, for example)\n",
    "\n",
    "# --------------------------------------------------------------\n",
    "# 6) Train/Test Split\n",
    "# --------------------------------------------------------------\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=y  # helps preserve class proportions\n",
    ")\n",
    "\n",
    "# --------------------------------------------------------------\n",
    "# 7) (Optional) Scale numeric features to help with convergence\n",
    "# --------------------------------------------------------------\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled  = scaler.transform(X_test)\n",
    "\n",
    "# --------------------------------------------------------------\n",
    "# 8) Multinomial Logistic Regression\n",
    "#    We'll use solver='lbfgs' which supports multi_class='multinomial'\n",
    "# --------------------------------------------------------------\n",
    "model = LogisticRegression(\n",
    "    multi_class='multinomial',\n",
    "    solver='lbfgs',\n",
    "    penalty='l2',\n",
    "    C=1.0,         # inverse of regularization strength\n",
    "    max_iter=500,  # increase if you see convergence warnings\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# --------------------------------------------------------------\n",
    "# 9) Evaluate Predictions\n",
    "# --------------------------------------------------------------\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "print(\"=== Confusion Matrix ===\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "print(\"\\n=== Classification Report ===\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# --------------------------------------------------------------\n",
    "# 10) Look at Coefficients\n",
    "#     model.coef_ is shape [n_classes, n_features]\n",
    "# --------------------------------------------------------------\n",
    "classes_ = model.classes_  # e.g., array([1,2,3,4,5,6,7]) if those are the labels\n",
    "coefs = model.coef_\n",
    "intercepts = model.intercept_\n",
    "\n",
    "print(\"\\n=== Multinomial Regression Coefficients ===\")\n",
    "for i, cls in enumerate(classes_):\n",
    "    print(f\"\\nClass '{cls}' vs. others:\")\n",
    "    print(\"  Intercept:\", intercepts[i])\n",
    "    for j, col in enumerate(predictors):\n",
    "        print(f\"  {col}: {coefs[i][j]:.4f}\")\n",
    "\n",
    "# --------------------------------------------------------------\n",
    "# 11) (Optional) Calculate an Ordinal Metric\n",
    "#     e.g., the average absolute difference |y_pred - y_true|\n",
    "# --------------------------------------------------------------\n",
    "def mean_ordinal_error(y_true, y_pred):\n",
    "    # Both are numeric arrays (e.g., 1..7)\n",
    "    return np.mean(np.abs(y_true - y_pred))\n",
    "\n",
    "moe = mean_ordinal_error(y_test, y_pred)\n",
    "print(f\"\\nMean Ordinal Error (0=perfect): {moe:.2f}\")\n",
    "\n",
    "# Another approach: Weighted MSE\n",
    "def mean_squared_ordinal_error(y_true, y_pred):\n",
    "    return np.mean((y_true - y_pred)**2)\n",
    "\n",
    "mse = mean_squared_ordinal_error(y_test, y_pred)\n",
    "print(f\"Mean Squared Ordinal Error: {mse:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b57dc3e9-ffe0-405a-ada0-f5f2937b8467",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a81e3bd3-280c-456c-b432-593714a30821",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "1e87f76b-fa59-422b-aa47-279499fe6afa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Difference columns created: ['diff_HandleHealth', 'diff_GunHowMany', 'diff_HandleImmig', 'diff_SocMed', 'diff_Age', 'diff_Fundamentalist', 'diff_Feminist', 'diff_Liberal', 'diff_Union', 'diff_BigBusiness', 'diff_Conservatives', 'diff_Gay', 'diff_Congress', 'diff_Muslims', 'diff_Jews', 'diff_Christ', 'diff_Police', 'diff_Transgender', 'diff_Scientist', 'diff_Blm']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"vote_gun_demo_opinions.csv\")\n",
    "\n",
    "# Example 2020 columns\n",
    "cols_2020 = [\n",
    "    \"20HandleHealth\", \"20GunHowMany\", \"20HandleImmig\", \"20SocMed\", \"20Age\",\n",
    "    \"20Fundamentalist\", \"20Feminist\", \"20Liberal\", \"20Union\", \"20BigBusiness\",\n",
    "    \"20Conservatives\", \"20Gay\", \"20Congress\", \"20Muslims\", \"20Jews\",\n",
    "    \"20Christ\", \"20Police\", \"20Transgender\", \"20Scientist\", \"20Blm\"\n",
    "]\n",
    "\n",
    "difference_columns = []\n",
    "\n",
    "for col_20 in cols_2020:\n",
    "    # Construct the matching 2016 column by replacing '20' with '16'\n",
    "    col_16 = col_20.replace(\"20\", \"16\", 1)  \n",
    "    # e.g., \"20HandleHealth\" -> \"16HandleHealth\"\n",
    "    \n",
    "    # Construct a new name for the difference column.\n",
    "    # Example: \"diff_HandleHealth\" if the column is \"20HandleHealth\"\n",
    "    # (You can pick your own naming pattern.)\n",
    "    diff_col = \"diff_\" + col_20[2:]  # removes '20', e.g. \"HandleHealth\"\n",
    "    \n",
    "    # Compute the difference and store in a new column\n",
    "    # Make sure both col_16 and col_20 exist and are numeric\n",
    "    df[diff_col] = df[col_20] - df[col_16]\n",
    "    \n",
    "    # Keep track of the new column name\n",
    "    difference_columns.append(diff_col)\n",
    "\n",
    "# Now 'difference_columns' contains the list of all new diff columns.\n",
    "print(\"Difference columns created:\", difference_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "4bc2693f-5ca4-4a2b-8e2e-4ff5ef635924",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Confusion Matrix ===\n",
      "[[102   1   3   1   1   0   1]\n",
      " [ 21   4   2   9   0   5   3]\n",
      " [ 34   2   5   4   0   0   1]\n",
      " [ 11   2   2   5   4   5  10]\n",
      " [  1   0   0   4   3   4  26]\n",
      " [  6   3   1   0   7   2  19]\n",
      " [  0   0   0   1   3   7  73]]\n",
      "\n",
      "=== Classification Report ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.58      0.94      0.72       109\n",
      "         2.0       0.33      0.09      0.14        44\n",
      "         3.0       0.38      0.11      0.17        46\n",
      "         4.0       0.21      0.13      0.16        39\n",
      "         5.0       0.17      0.08      0.11        38\n",
      "         6.0       0.09      0.05      0.07        38\n",
      "         7.0       0.55      0.87      0.67        84\n",
      "\n",
      "    accuracy                           0.49       398\n",
      "   macro avg       0.33      0.32      0.29       398\n",
      "weighted avg       0.40      0.49      0.41       398\n",
      "\n",
      "\n",
      "=== Multinomial Regression Coefficients ===\n",
      "\n",
      "Class '1.0' vs. others:\n",
      "  Intercept: 0.1094863152112759\n",
      "  diff_HandleHealth: 1.3839\n",
      "  diff_GunHowMany: -0.0841\n",
      "  diff_HandleImmig: 1.2625\n",
      "  diff_SocMed: -0.0527\n",
      "  diff_Age: 0.0416\n",
      "  diff_Fundamentalist: -0.0321\n",
      "  diff_Feminist: -0.0227\n",
      "  diff_Liberal: -0.0244\n",
      "  diff_Union: -0.1489\n",
      "  diff_BigBusiness: 0.0130\n",
      "  diff_Conservatives: -0.1537\n",
      "  diff_Gay: 0.1235\n",
      "  diff_Congress: 0.3726\n",
      "  diff_Muslims: -0.0827\n",
      "  diff_Jews: 0.1833\n",
      "  diff_Christ: 0.1438\n",
      "  diff_Police: -0.0611\n",
      "  diff_Transgender: -0.0380\n",
      "  diff_Scientist: 0.0400\n",
      "  diff_Blm: 0.1165\n",
      "\n",
      "Class '2.0' vs. others:\n",
      "  Intercept: 0.20119131096192014\n",
      "  diff_HandleHealth: 0.6247\n",
      "  diff_GunHowMany: -0.0012\n",
      "  diff_HandleImmig: 0.7487\n",
      "  diff_SocMed: 0.0030\n",
      "  diff_Age: -0.0836\n",
      "  diff_Fundamentalist: -0.0328\n",
      "  diff_Feminist: 0.0458\n",
      "  diff_Liberal: -0.0075\n",
      "  diff_Union: -0.1602\n",
      "  diff_BigBusiness: -0.0474\n",
      "  diff_Conservatives: -0.2809\n",
      "  diff_Gay: -0.0125\n",
      "  diff_Congress: -0.0283\n",
      "  diff_Muslims: 0.0142\n",
      "  diff_Jews: 0.0384\n",
      "  diff_Christ: 0.1282\n",
      "  diff_Police: 0.0273\n",
      "  diff_Transgender: -0.0153\n",
      "  diff_Scientist: 0.0490\n",
      "  diff_Blm: 0.1254\n",
      "\n",
      "Class '3.0' vs. others:\n",
      "  Intercept: 0.09201442525703547\n",
      "  diff_HandleHealth: 0.9877\n",
      "  diff_GunHowMany: 0.1830\n",
      "  diff_HandleImmig: 0.5062\n",
      "  diff_SocMed: 0.0774\n",
      "  diff_Age: 0.0788\n",
      "  diff_Fundamentalist: 0.0545\n",
      "  diff_Feminist: -0.0095\n",
      "  diff_Liberal: 0.0147\n",
      "  diff_Union: 0.0798\n",
      "  diff_BigBusiness: 0.0535\n",
      "  diff_Conservatives: -0.2706\n",
      "  diff_Gay: 0.0328\n",
      "  diff_Congress: -0.0027\n",
      "  diff_Muslims: -0.1781\n",
      "  diff_Jews: 0.1516\n",
      "  diff_Christ: 0.0866\n",
      "  diff_Police: -0.2547\n",
      "  diff_Transgender: -0.0944\n",
      "  diff_Scientist: 0.1121\n",
      "  diff_Blm: 0.1606\n",
      "\n",
      "Class '4.0' vs. others:\n",
      "  Intercept: 0.5339291058241731\n",
      "  diff_HandleHealth: 0.1159\n",
      "  diff_GunHowMany: 0.0150\n",
      "  diff_HandleImmig: -0.0911\n",
      "  diff_SocMed: -0.0637\n",
      "  diff_Age: -0.1662\n",
      "  diff_Fundamentalist: 0.0422\n",
      "  diff_Feminist: 0.0150\n",
      "  diff_Liberal: 0.0093\n",
      "  diff_Union: 0.0876\n",
      "  diff_BigBusiness: -0.0665\n",
      "  diff_Conservatives: 0.1029\n",
      "  diff_Gay: -0.1285\n",
      "  diff_Congress: -0.1675\n",
      "  diff_Muslims: -0.0245\n",
      "  diff_Jews: 0.0073\n",
      "  diff_Christ: -0.0293\n",
      "  diff_Police: 0.0958\n",
      "  diff_Transgender: 0.0939\n",
      "  diff_Scientist: -0.0624\n",
      "  diff_Blm: 0.0645\n",
      "\n",
      "Class '5.0' vs. others:\n",
      "  Intercept: -0.012588005334702926\n",
      "  diff_HandleHealth: -0.7051\n",
      "  diff_GunHowMany: 0.0145\n",
      "  diff_HandleImmig: -0.6211\n",
      "  diff_SocMed: -0.0790\n",
      "  diff_Age: 0.0441\n",
      "  diff_Fundamentalist: 0.0881\n",
      "  diff_Feminist: -0.0275\n",
      "  diff_Liberal: 0.0805\n",
      "  diff_Union: 0.0608\n",
      "  diff_BigBusiness: 0.0688\n",
      "  diff_Conservatives: 0.2824\n",
      "  diff_Gay: -0.0726\n",
      "  diff_Congress: -0.0436\n",
      "  diff_Muslims: 0.1140\n",
      "  diff_Jews: -0.1283\n",
      "  diff_Christ: -0.1410\n",
      "  diff_Police: 0.0015\n",
      "  diff_Transgender: 0.1476\n",
      "  diff_Scientist: 0.0010\n",
      "  diff_Blm: -0.1859\n",
      "\n",
      "Class '6.0' vs. others:\n",
      "  Intercept: 0.14880232400298565\n",
      "  diff_HandleHealth: -0.3496\n",
      "  diff_GunHowMany: -0.0490\n",
      "  diff_HandleImmig: -0.7030\n",
      "  diff_SocMed: 0.1192\n",
      "  diff_Age: 0.0000\n",
      "  diff_Fundamentalist: -0.0707\n",
      "  diff_Feminist: 0.0065\n",
      "  diff_Liberal: -0.0021\n",
      "  diff_Union: -0.0119\n",
      "  diff_BigBusiness: 0.0655\n",
      "  diff_Conservatives: 0.1482\n",
      "  diff_Gay: 0.0946\n",
      "  diff_Congress: -0.0957\n",
      "  diff_Muslims: 0.0603\n",
      "  diff_Jews: -0.0933\n",
      "  diff_Christ: -0.0641\n",
      "  diff_Police: -0.0278\n",
      "  diff_Transgender: -0.1648\n",
      "  diff_Scientist: 0.0008\n",
      "  diff_Blm: -0.1627\n",
      "\n",
      "Class '7.0' vs. others:\n",
      "  Intercept: -1.0728354759226948\n",
      "  diff_HandleHealth: -2.0575\n",
      "  diff_GunHowMany: -0.0782\n",
      "  diff_HandleImmig: -1.1021\n",
      "  diff_SocMed: -0.0043\n",
      "  diff_Age: 0.0853\n",
      "  diff_Fundamentalist: -0.0492\n",
      "  diff_Feminist: -0.0077\n",
      "  diff_Liberal: -0.0704\n",
      "  diff_Union: 0.0927\n",
      "  diff_BigBusiness: -0.0868\n",
      "  diff_Conservatives: 0.1717\n",
      "  diff_Gay: -0.0372\n",
      "  diff_Congress: -0.0349\n",
      "  diff_Muslims: 0.0969\n",
      "  diff_Jews: -0.1590\n",
      "  diff_Christ: -0.1241\n",
      "  diff_Police: 0.2190\n",
      "  diff_Transgender: 0.0710\n",
      "  diff_Scientist: -0.1406\n",
      "  diff_Blm: -0.1184\n",
      "\n",
      "Mean Ordinal Error (0=perfect): 1.03\n",
      "Mean Squared Ordinal Error: 2.66\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "# 1) Read the CSV file\n",
    "\n",
    "# --------------------------------------------------------------\n",
    "# 2) Prepare columns: define your 2020 numeric features + 16VoteSum\n",
    "#    Adjust this list to match your actual numeric 2020 columns\n",
    "# --------------------------------------------------------------\n",
    "twenty_features = ['diff_HandleHealth', 'diff_GunHowMany', 'diff_HandleImmig', 'diff_SocMed', 'diff_Age', 'diff_Fundamentalist', 'diff_Feminist', 'diff_Liberal', 'diff_Union', 'diff_BigBusiness', 'diff_Conservatives', 'diff_Gay', 'diff_Congress', 'diff_Muslims', 'diff_Jews', 'diff_Christ', 'diff_Police', 'diff_Transgender', 'diff_Scientist', 'diff_Blm']\n",
    "\n",
    "# We'll include 16VoteSum as part of our predictors\n",
    "predictors = twenty_features \n",
    "\n",
    "# --------------------------------------------------------------\n",
    "# 3) Ensure 16VoteSum and 20VoteSum are numeric\n",
    "# --------------------------------------------------------------\n",
    "mapping_16 = {\n",
    "    \"Strong Democrat\": 1,\n",
    "    \"Not very strong Democrat\": 2,\n",
    "    \"Independent-Democrat\": 3,\n",
    "    \"Independent\": 4,\n",
    "    \"Independent-Republican\": 5,\n",
    "    \"Not very strong Republican\": 6,\n",
    "    \"Strong Republican\": 7\n",
    "}\n",
    "\n",
    "# For 2016\n",
    "df[\"20VoteSum\"] = df[\"20VoteSum\"].map(mapping_16)\n",
    "\n",
    "# --------------------------------------------------------------\n",
    "# 4) Drop rows where any needed column is missing\n",
    "# --------------------------------------------------------------\n",
    "df_clean = df.dropna(subset=predictors + [\"20VoteSum\"]).copy()\n",
    "\n",
    "# --------------------------------------------------------------\n",
    "# 5) Create X (predictors) and y (target)\n",
    "# --------------------------------------------------------------\n",
    "X = df_clean[predictors]\n",
    "y = df_clean[\"20VoteSum\"]  # This is multiclass (1..7, for example)\n",
    "\n",
    "# --------------------------------------------------------------\n",
    "# 6) Train/Test Split\n",
    "# --------------------------------------------------------------\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=y  # helps preserve class proportions\n",
    ")\n",
    "\n",
    "# --------------------------------------------------------------\n",
    "# 7) (Optional) Scale numeric features to help with convergence\n",
    "# --------------------------------------------------------------\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled  = scaler.transform(X_test)\n",
    "\n",
    "# --------------------------------------------------------------\n",
    "# 8) Multinomial Logistic Regression\n",
    "#    We'll use solver='lbfgs' which supports multi_class='multinomial'\n",
    "# --------------------------------------------------------------\n",
    "model = LogisticRegression(\n",
    "    multi_class='multinomial',\n",
    "    solver='lbfgs',\n",
    "    penalty='l2',\n",
    "    C=1.0,         # inverse of regularization strength\n",
    "    max_iter=500,  # increase if you see convergence warnings\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# --------------------------------------------------------------\n",
    "# 9) Evaluate Predictions\n",
    "# --------------------------------------------------------------\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "print(\"=== Confusion Matrix ===\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "print(\"\\n=== Classification Report ===\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# --------------------------------------------------------------\n",
    "# 10) Look at Coefficients\n",
    "#     model.coef_ is shape [n_classes, n_features]\n",
    "# --------------------------------------------------------------\n",
    "classes_ = model.classes_  # e.g., array([1,2,3,4,5,6,7]) if those are the labels\n",
    "coefs = model.coef_\n",
    "intercepts = model.intercept_\n",
    "\n",
    "print(\"\\n=== Multinomial Regression Coefficients ===\")\n",
    "for i, cls in enumerate(classes_):\n",
    "    print(f\"\\nClass '{cls}' vs. others:\")\n",
    "    print(\"  Intercept:\", intercepts[i])\n",
    "    for j, col in enumerate(predictors):\n",
    "        print(f\"  {col}: {coefs[i][j]:.4f}\")\n",
    "\n",
    "# --------------------------------------------------------------\n",
    "# 11) (Optional) Calculate an Ordinal Metric\n",
    "#     e.g., the average absolute difference |y_pred - y_true|\n",
    "# --------------------------------------------------------------\n",
    "def mean_ordinal_error(y_true, y_pred):\n",
    "    # Both are numeric arrays (e.g., 1..7)\n",
    "    return np.mean(np.abs(y_true - y_pred))\n",
    "\n",
    "moe = mean_ordinal_error(y_test, y_pred)\n",
    "print(f\"\\nMean Ordinal Error (0=perfect): {moe:.2f}\")\n",
    "\n",
    "# Another approach: Weighted MSE\n",
    "def mean_squared_ordinal_error(y_true, y_pred):\n",
    "    return np.mean((y_true - y_pred)**2)\n",
    "\n",
    "mse = mean_squared_ordinal_error(y_test, y_pred)\n",
    "print(f\"Mean Squared Ordinal Error: {mse:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "840b2c86-a012-4dfb-9b14-0f6ed0acdca5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa26a5ed-2bbf-4b11-9aef-0edb65082b9b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae0d583d-55ec-4c7f-9a61-cc3d50ce29e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "a44ea0b4-31b6-4c43-b1ad-1737d4344ede",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Difference columns created: ['diff_HandleHealth', 'diff_GunHowMany', 'diff_HandleImmig', 'diff_SocMed', 'diff_Age', 'diff_Fundamentalist', 'diff_Feminist', 'diff_Liberal', 'diff_Union', 'diff_BigBusiness', 'diff_Conservatives', 'diff_Gay', 'diff_Congress', 'diff_Muslims', 'diff_Jews', 'diff_Christ', 'diff_Police', 'diff_Transgender', 'diff_Scientist', 'diff_Blm']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"vote_gun_demo_opinions.csv\")\n",
    "\n",
    "# Example 2020 columns\n",
    "cols_2020 = [\n",
    "    \"20HandleHealth\", \"20GunHowMany\", \"20HandleImmig\", \"20SocMed\", \"20Age\",\n",
    "    \"20Fundamentalist\", \"20Feminist\", \"20Liberal\", \"20Union\", \"20BigBusiness\",\n",
    "    \"20Conservatives\", \"20Gay\", \"20Congress\", \"20Muslims\", \"20Jews\",\n",
    "    \"20Christ\", \"20Police\", \"20Transgender\", \"20Scientist\", \"20Blm\"\n",
    "]\n",
    "\n",
    "difference_columns = []\n",
    "\n",
    "for col_20 in cols_2020:\n",
    "    # Construct the matching 2016 column by replacing '20' with '16'\n",
    "    col_16 = col_20.replace(\"20\", \"16\", 1)  \n",
    "    # e.g., \"20HandleHealth\" -> \"16HandleHealth\"\n",
    "    \n",
    "    # Construct a new name for the difference column.\n",
    "    # Example: \"diff_HandleHealth\" if the column is \"20HandleHealth\"\n",
    "    # (You can pick your own naming pattern.)\n",
    "    diff_col = \"diff_\" + col_20[2:]  # removes '20', e.g. \"HandleHealth\"\n",
    "    \n",
    "    # Compute the difference and store in a new column\n",
    "    # Make sure both col_16 and col_20 exist and are numeric\n",
    "    df[diff_col] = df[col_20] - df[col_16]\n",
    "    \n",
    "    # Keep track of the new column name\n",
    "    difference_columns.append(diff_col)\n",
    "\n",
    "# Now 'difference_columns' contains the list of all new diff columns.\n",
    "print(\"Difference columns created:\", difference_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "b4f7c7a1-819d-485e-ae90-53acb2655cef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       7.0\n",
      "1       4.0\n",
      "2       5.0\n",
      "3       4.0\n",
      "4       1.0\n",
      "       ... \n",
      "2834    1.0\n",
      "2835    1.0\n",
      "2836    1.0\n",
      "2837    2.0\n",
      "2838    7.0\n",
      "Name: 20VoteSum, Length: 2839, dtype: float64\n",
      "=== Confusion Matrix ===\n",
      "[[97  3  7  1  1  0  0]\n",
      " [22  4  4  8  1  3  1]\n",
      " [17  6 19  3  1  0  0]\n",
      " [ 4  3  7  6  9  6  4]\n",
      " [ 1  0  1  7  5  5 19]\n",
      " [ 1  0  3  4 10  3 17]\n",
      " [ 0  1  0  4  8  4 67]]\n",
      "\n",
      "=== Classification Report ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.68      0.89      0.77       109\n",
      "         2.0       0.24      0.09      0.13        43\n",
      "         3.0       0.46      0.41      0.44        46\n",
      "         4.0       0.18      0.15      0.17        39\n",
      "         5.0       0.14      0.13      0.14        38\n",
      "         6.0       0.14      0.08      0.10        38\n",
      "         7.0       0.62      0.80      0.70        84\n",
      "\n",
      "    accuracy                           0.51       397\n",
      "   macro avg       0.35      0.37      0.35       397\n",
      "weighted avg       0.44      0.51      0.46       397\n",
      "\n",
      "\n",
      "=== Multinomial Regression Coefficients ===\n",
      "\n",
      "Class '1.0' vs. others:\n",
      "  Intercept: -0.42381073355584326\n",
      "  diff_HandleHealth: 0.8403\n",
      "  diff_GunHowMany: -0.1112\n",
      "  diff_HandleImmig: 0.9258\n",
      "  diff_SocMed: 0.0432\n",
      "  diff_Age: 0.0447\n",
      "  diff_Fundamentalist: 0.0389\n",
      "  diff_Feminist: 0.0282\n",
      "  diff_Liberal: 0.1884\n",
      "  diff_Union: -0.1782\n",
      "  diff_BigBusiness: -0.0498\n",
      "  diff_Conservatives: -0.2230\n",
      "  diff_Gay: 0.1075\n",
      "  diff_Congress: 0.3444\n",
      "  diff_Muslims: -0.0381\n",
      "  diff_Jews: 0.1573\n",
      "  diff_Christ: 0.1523\n",
      "  diff_Police: -0.1445\n",
      "  diff_Transgender: -0.0669\n",
      "  diff_Scientist: 0.0861\n",
      "  diff_Blm: 0.1647\n",
      "  16VoteSum: -2.5329\n",
      "\n",
      "Class '2.0' vs. others:\n",
      "  Intercept: 0.39821112051955915\n",
      "  diff_HandleHealth: 0.3598\n",
      "  diff_GunHowMany: -0.0386\n",
      "  diff_HandleImmig: 0.5773\n",
      "  diff_SocMed: 0.0435\n",
      "  diff_Age: -0.1164\n",
      "  diff_Fundamentalist: 0.0120\n",
      "  diff_Feminist: 0.0219\n",
      "  diff_Liberal: 0.1746\n",
      "  diff_Union: -0.2073\n",
      "  diff_BigBusiness: -0.0906\n",
      "  diff_Conservatives: -0.3495\n",
      "  diff_Gay: -0.0275\n",
      "  diff_Congress: -0.0511\n",
      "  diff_Muslims: 0.0710\n",
      "  diff_Jews: 0.0719\n",
      "  diff_Christ: 0.1419\n",
      "  diff_Police: -0.0221\n",
      "  diff_Transgender: -0.0216\n",
      "  diff_Scientist: 0.0658\n",
      "  diff_Blm: 0.1398\n",
      "  16VoteSum: -1.2746\n",
      "\n",
      "Class '3.0' vs. others:\n",
      "  Intercept: 0.5099076714729331\n",
      "  diff_HandleHealth: 0.9614\n",
      "  diff_GunHowMany: 0.1781\n",
      "  diff_HandleImmig: 0.4815\n",
      "  diff_SocMed: 0.1092\n",
      "  diff_Age: 0.0143\n",
      "  diff_Fundamentalist: 0.0752\n",
      "  diff_Feminist: -0.0425\n",
      "  diff_Liberal: 0.0957\n",
      "  diff_Union: 0.0529\n",
      "  diff_BigBusiness: 0.0187\n",
      "  diff_Conservatives: -0.2931\n",
      "  diff_Gay: 0.0592\n",
      "  diff_Congress: 0.0029\n",
      "  diff_Muslims: -0.1425\n",
      "  diff_Jews: 0.1894\n",
      "  diff_Christ: 0.1075\n",
      "  diff_Police: -0.2725\n",
      "  diff_Transgender: -0.1184\n",
      "  diff_Scientist: 0.1253\n",
      "  diff_Blm: 0.1477\n",
      "  16VoteSum: -0.3915\n",
      "\n",
      "Class '4.0' vs. others:\n",
      "  Intercept: 0.945402373409165\n",
      "  diff_HandleHealth: 0.1929\n",
      "  diff_GunHowMany: 0.0454\n",
      "  diff_HandleImmig: -0.0960\n",
      "  diff_SocMed: -0.0779\n",
      "  diff_Age: -0.1514\n",
      "  diff_Fundamentalist: 0.0184\n",
      "  diff_Feminist: 0.0459\n",
      "  diff_Liberal: 0.0339\n",
      "  diff_Union: 0.0680\n",
      "  diff_BigBusiness: -0.0412\n",
      "  diff_Conservatives: 0.0347\n",
      "  diff_Gay: -0.0459\n",
      "  diff_Congress: -0.2213\n",
      "  diff_Muslims: 0.0152\n",
      "  diff_Jews: 0.0035\n",
      "  diff_Christ: 0.0203\n",
      "  diff_Police: 0.1976\n",
      "  diff_Transgender: 0.0504\n",
      "  diff_Scientist: -0.0970\n",
      "  diff_Blm: 0.1148\n",
      "  16VoteSum: 0.0341\n",
      "\n",
      "Class '5.0' vs. others:\n",
      "  Intercept: 0.26123764533637506\n",
      "  diff_HandleHealth: -0.5383\n",
      "  diff_GunHowMany: 0.0337\n",
      "  diff_HandleImmig: -0.5441\n",
      "  diff_SocMed: -0.1070\n",
      "  diff_Age: 0.0592\n",
      "  diff_Fundamentalist: 0.0797\n",
      "  diff_Feminist: -0.0448\n",
      "  diff_Liberal: -0.0249\n",
      "  diff_Union: 0.0749\n",
      "  diff_BigBusiness: 0.0850\n",
      "  diff_Conservatives: 0.3038\n",
      "  diff_Gay: -0.0900\n",
      "  diff_Congress: -0.0673\n",
      "  diff_Muslims: 0.0754\n",
      "  diff_Jews: -0.0937\n",
      "  diff_Christ: -0.1753\n",
      "  diff_Police: 0.0170\n",
      "  diff_Transgender: 0.1840\n",
      "  diff_Scientist: 0.0098\n",
      "  diff_Blm: -0.1682\n",
      "  16VoteSum: 0.6655\n",
      "\n",
      "Class '6.0' vs. others:\n",
      "  Intercept: 0.18425369471753933\n",
      "  diff_HandleHealth: -0.1128\n",
      "  diff_GunHowMany: -0.0342\n",
      "  diff_HandleImmig: -0.5532\n",
      "  diff_SocMed: 0.0916\n",
      "  diff_Age: 0.0231\n",
      "  diff_Fundamentalist: -0.1017\n",
      "  diff_Feminist: -0.0130\n",
      "  diff_Liberal: -0.1560\n",
      "  diff_Union: 0.0185\n",
      "  diff_BigBusiness: 0.1031\n",
      "  diff_Conservatives: 0.2223\n",
      "  diff_Gay: 0.0603\n",
      "  diff_Congress: -0.0625\n",
      "  diff_Muslims: -0.0028\n",
      "  diff_Jews: -0.1072\n",
      "  diff_Christ: -0.0860\n",
      "  diff_Police: -0.0086\n",
      "  diff_Transgender: -0.1129\n",
      "  diff_Scientist: -0.0090\n",
      "  diff_Blm: -0.1716\n",
      "  16VoteSum: 1.1840\n",
      "\n",
      "Class '7.0' vs. others:\n",
      "  Intercept: -1.8752017718997258\n",
      "  diff_HandleHealth: -1.7033\n",
      "  diff_GunHowMany: -0.0732\n",
      "  diff_HandleImmig: -0.7913\n",
      "  diff_SocMed: -0.1027\n",
      "  diff_Age: 0.1266\n",
      "  diff_Fundamentalist: -0.1226\n",
      "  diff_Feminist: 0.0044\n",
      "  diff_Liberal: -0.3117\n",
      "  diff_Union: 0.1711\n",
      "  diff_BigBusiness: -0.0253\n",
      "  diff_Conservatives: 0.3049\n",
      "  diff_Gay: -0.0636\n",
      "  diff_Congress: 0.0548\n",
      "  diff_Muslims: 0.0218\n",
      "  diff_Jews: -0.2212\n",
      "  diff_Christ: -0.1606\n",
      "  diff_Police: 0.2332\n",
      "  diff_Transgender: 0.0853\n",
      "  diff_Scientist: -0.1810\n",
      "  diff_Blm: -0.2271\n",
      "  16VoteSum: 2.3154\n",
      "\n",
      "Mean Ordinal Error (0=perfect): 0.83\n",
      "Mean Squared Ordinal Error: 1.77\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "# 1) Read the CSV file\n",
    "\n",
    "# --------------------------------------------------------------\n",
    "# 2) Prepare columns: define your 2020 numeric features + 16VoteSum\n",
    "#    Adjust this list to match your actual numeric 2020 columns\n",
    "# --------------------------------------------------------------\n",
    "twenty_features = ['diff_HandleHealth', 'diff_GunHowMany', 'diff_HandleImmig', 'diff_SocMed', 'diff_Age', 'diff_Fundamentalist', 'diff_Feminist', 'diff_Liberal', 'diff_Union', 'diff_BigBusiness', 'diff_Conservatives', 'diff_Gay', 'diff_Congress', 'diff_Muslims', 'diff_Jews', 'diff_Christ', 'diff_Police', 'diff_Transgender', 'diff_Scientist', 'diff_Blm']\n",
    "\n",
    "\n",
    "# We'll include 16VoteSum as part of our predictors\n",
    "predictors = twenty_features + [\"16VoteSum\"]\n",
    "\n",
    "# --------------------------------------------------------------\n",
    "# 3) Ensure 16VoteSum and 20VoteSum are numeric\n",
    "# --------------------------------------------------------------\n",
    "mapping_16 = {\n",
    "    \"Strong Democrat\": 1,\n",
    "    \"Not very strong Democrat\": 2,\n",
    "    \"Independent-Democrat\": 3,\n",
    "    \"Independent\": 4,\n",
    "    \"Independent-Republican\": 5,\n",
    "    \"Not very strong Republican\": 6,\n",
    "    \"Strong Republican\": 7\n",
    "}\n",
    "\n",
    "# For 2016\n",
    "df[\"16VoteSum\"] = df[\"16VoteSum\"].map(mapping_16)\n",
    "df[\"20VoteSum\"] = df[\"20VoteSum\"].map(mapping_16)\n",
    "print(df[\"20VoteSum\"])\n",
    "\n",
    "# --------------------------------------------------------------\n",
    "# 4) Drop rows where any needed column is missing\n",
    "# --------------------------------------------------------------\n",
    "df_clean = df.dropna(subset=predictors + [\"20VoteSum\"]).copy()\n",
    "\n",
    "# --------------------------------------------------------------\n",
    "# 5) Create X (predictors) and y (target)\n",
    "# --------------------------------------------------------------\n",
    "X = df_clean[predictors]\n",
    "y = df_clean[\"20VoteSum\"]  # This is multiclass (1..7, for example)\n",
    "\n",
    "# --------------------------------------------------------------\n",
    "# 6) Train/Test Split\n",
    "# --------------------------------------------------------------\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=y  # helps preserve class proportions\n",
    ")\n",
    "\n",
    "# --------------------------------------------------------------\n",
    "# 7) (Optional) Scale numeric features to help with convergence\n",
    "# --------------------------------------------------------------\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled  = scaler.transform(X_test)\n",
    "\n",
    "# --------------------------------------------------------------\n",
    "# 8) Multinomial Logistic Regression\n",
    "#    We'll use solver='lbfgs' which supports multi_class='multinomial'\n",
    "# --------------------------------------------------------------\n",
    "model = LogisticRegression(\n",
    "    multi_class='multinomial',\n",
    "    solver='lbfgs',\n",
    "    penalty='l2',\n",
    "    C=1.0,         # inverse of regularization strength\n",
    "    max_iter=500,  # increase if you see convergence warnings\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# --------------------------------------------------------------\n",
    "# 9) Evaluate Predictions\n",
    "# --------------------------------------------------------------\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "print(\"=== Confusion Matrix ===\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "print(\"\\n=== Classification Report ===\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# --------------------------------------------------------------\n",
    "# 10) Look at Coefficients\n",
    "#     model.coef_ is shape [n_classes, n_features]\n",
    "# --------------------------------------------------------------\n",
    "classes_ = model.classes_  # e.g., array([1,2,3,4,5,6,7]) if those are the labels\n",
    "coefs = model.coef_\n",
    "intercepts = model.intercept_\n",
    "\n",
    "print(\"\\n=== Multinomial Regression Coefficients ===\")\n",
    "for i, cls in enumerate(classes_):\n",
    "    print(f\"\\nClass '{cls}' vs. others:\")\n",
    "    print(\"  Intercept:\", intercepts[i])\n",
    "    for j, col in enumerate(predictors):\n",
    "        print(f\"  {col}: {coefs[i][j]:.4f}\")\n",
    "\n",
    "# --------------------------------------------------------------\n",
    "# 11) (Optional) Calculate an Ordinal Metric\n",
    "#     e.g., the average absolute difference |y_pred - y_true|\n",
    "# --------------------------------------------------------------\n",
    "def mean_ordinal_error(y_true, y_pred):\n",
    "    # Both are numeric arrays (e.g., 1..7)\n",
    "    return np.mean(np.abs(y_true - y_pred))\n",
    "\n",
    "moe = mean_ordinal_error(y_test, y_pred)\n",
    "print(f\"\\nMean Ordinal Error (0=perfect): {moe:.2f}\")\n",
    "\n",
    "# Another approach: Weighted MSE\n",
    "def mean_squared_ordinal_error(y_true, y_pred):\n",
    "    return np.mean((y_true - y_pred)**2)\n",
    "\n",
    "mse = mean_squared_ordinal_error(y_test, y_pred)\n",
    "print(f\"Mean Squared Ordinal Error: {mse:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e824531-f238-45c7-b0c6-b86b95e8b420",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d030a1c6-c80a-42bd-b171-ce38e51b251e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d495668d-90d7-4a9e-9b31-0763e5c0fe1b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "c14161d6-ad76-4cf5-b263-58e4915d2e38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Difference columns created: ['diff_HandleHealth', 'diff_GunHowMany', 'diff_HandleImmig', 'diff_SocMed', 'diff_Age', 'diff_Fundamentalist', 'diff_Feminist', 'diff_Liberal', 'diff_Union', 'diff_BigBusiness', 'diff_Conservatives', 'diff_Gay', 'diff_Congress', 'diff_Muslims', 'diff_Jews', 'diff_Christ', 'diff_Police', 'diff_Transgender', 'diff_Scientist', 'diff_Blm']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"vote_gun_demo_opinions.csv\")\n",
    "\n",
    "# Example 2020 columns\n",
    "cols_2020 = [\n",
    "    \"20HandleHealth\", \"20GunHowMany\", \"20HandleImmig\", \"20SocMed\", \"20Age\",\n",
    "    \"20Fundamentalist\", \"20Feminist\", \"20Liberal\", \"20Union\", \"20BigBusiness\",\n",
    "    \"20Conservatives\", \"20Gay\", \"20Congress\", \"20Muslims\", \"20Jews\",\n",
    "    \"20Christ\", \"20Police\", \"20Transgender\", \"20Scientist\", \"20Blm\"\n",
    "]\n",
    "\n",
    "difference_columns = []\n",
    "\n",
    "for col_20 in cols_2020:\n",
    "    # Construct the matching 2016 column by replacing '20' with '16'\n",
    "    col_16 = col_20.replace(\"20\", \"16\", 1)  \n",
    "    # e.g., \"20HandleHealth\" -> \"16HandleHealth\"\n",
    "    \n",
    "    # Construct a new name for the difference column.\n",
    "    # Example: \"diff_HandleHealth\" if the column is \"20HandleHealth\"\n",
    "    # (You can pick your own naming pattern.)\n",
    "    diff_col = \"diff_\" + col_20[2:]  # removes '20', e.g. \"HandleHealth\"\n",
    "    \n",
    "    # Compute the difference and store in a new column\n",
    "    # Make sure both col_16 and col_20 exist and are numeric\n",
    "    df[diff_col] = df[col_20] - df[col_16]\n",
    "    \n",
    "    # Keep track of the new column name\n",
    "    difference_columns.append(diff_col)\n",
    "\n",
    "# Now 'difference_columns' contains the list of all new diff columns.\n",
    "print(\"Difference columns created:\", difference_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "12749907-407c-4bdc-9393-2015c59ea4c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       7.0\n",
      "1       4.0\n",
      "2       5.0\n",
      "3       4.0\n",
      "4       1.0\n",
      "       ... \n",
      "2834    1.0\n",
      "2835    1.0\n",
      "2836    1.0\n",
      "2837    2.0\n",
      "2838    7.0\n",
      "Name: 20VoteSum, Length: 2839, dtype: float64\n",
      "=== Confusion Matrix ===\n",
      "[[98  4  5  0  1  1  0]\n",
      " [20  5  5  5  1  5  2]\n",
      " [19  4 17  5  1  0  0]\n",
      " [ 3  6  6  9  7  6  2]\n",
      " [ 1  0  1  5  8  8 15]\n",
      " [ 1  1  1  5 10  3 17]\n",
      " [ 0  1  0  3  7  5 68]]\n",
      "\n",
      "=== Classification Report ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.69      0.90      0.78       109\n",
      "         2.0       0.24      0.12      0.16        43\n",
      "         3.0       0.49      0.37      0.42        46\n",
      "         4.0       0.28      0.23      0.25        39\n",
      "         5.0       0.23      0.21      0.22        38\n",
      "         6.0       0.11      0.08      0.09        38\n",
      "         7.0       0.65      0.81      0.72        84\n",
      "\n",
      "    accuracy                           0.52       397\n",
      "   macro avg       0.38      0.39      0.38       397\n",
      "weighted avg       0.47      0.52      0.49       397\n",
      "\n",
      "\n",
      "=== Multinomial Regression Coefficients ===\n",
      "\n",
      "Class '1.0' vs. others:\n",
      "  Intercept: -0.4928346652565915\n",
      "  diff_HandleHealth: 0.4121\n",
      "  diff_GunHowMany: 0.0273\n",
      "  diff_HandleImmig: 0.3803\n",
      "  diff_SocMed: 0.1027\n",
      "  diff_Age: 0.0587\n",
      "  diff_Fundamentalist: 0.0434\n",
      "  diff_Feminist: -0.1239\n",
      "  diff_Liberal: -0.0904\n",
      "  diff_Union: -0.3086\n",
      "  diff_BigBusiness: 0.0643\n",
      "  diff_Conservatives: 0.2835\n",
      "  diff_Gay: 0.1023\n",
      "  diff_Congress: 0.0252\n",
      "  diff_Muslims: 0.1312\n",
      "  diff_Jews: 0.1032\n",
      "  diff_Christ: 0.0714\n",
      "  diff_Police: -0.0980\n",
      "  diff_Transgender: -0.0808\n",
      "  diff_Scientist: -0.0125\n",
      "  diff_Blm: -0.1226\n",
      "  20HandleHealth: 0.1442\n",
      "  20GunHowMany: -0.1089\n",
      "  20HandleImmig: 0.2605\n",
      "  20SocMed: -0.0817\n",
      "  20Age: 0.1938\n",
      "  20Fundamentalist: 0.1373\n",
      "  20Feminist: 0.3278\n",
      "  20Liberal: 0.7381\n",
      "  20Union: 0.1753\n",
      "  20BigBusiness: -0.0496\n",
      "  20Conservatives: -1.0765\n",
      "  20Gay: 0.1657\n",
      "  20Congress: 0.0751\n",
      "  20Muslims: -0.0936\n",
      "  20Jews: 0.0812\n",
      "  20Christ: 0.2458\n",
      "  20Police: -0.1021\n",
      "  20Transgender: -0.2254\n",
      "  20Scientist: 0.1728\n",
      "  20Blm: 0.5681\n",
      "  16VoteSum: -2.2097\n",
      "\n",
      "Class '2.0' vs. others:\n",
      "  Intercept: 0.31589492470938046\n",
      "  diff_HandleHealth: 0.0241\n",
      "  diff_GunHowMany: 0.2516\n",
      "  diff_HandleImmig: 0.4885\n",
      "  diff_SocMed: -0.1222\n",
      "  diff_Age: -0.0834\n",
      "  diff_Fundamentalist: -0.0154\n",
      "  diff_Feminist: -0.0762\n",
      "  diff_Liberal: 0.0009\n",
      "  diff_Union: -0.3013\n",
      "  diff_BigBusiness: -0.0513\n",
      "  diff_Conservatives: -0.0458\n",
      "  diff_Gay: -0.1167\n",
      "  diff_Congress: -0.0974\n",
      "  diff_Muslims: 0.0667\n",
      "  diff_Jews: 0.0756\n",
      "  diff_Christ: 0.1692\n",
      "  diff_Police: 0.0098\n",
      "  diff_Transgender: -0.0428\n",
      "  diff_Scientist: 0.1436\n",
      "  diff_Blm: 0.1062\n",
      "  20HandleHealth: 0.3546\n",
      "  20GunHowMany: -0.3759\n",
      "  20HandleImmig: -0.1631\n",
      "  20SocMed: 0.3344\n",
      "  20Age: -0.0614\n",
      "  20Fundamentalist: 0.1441\n",
      "  20Feminist: 0.1916\n",
      "  20Liberal: 0.4196\n",
      "  20Union: 0.1856\n",
      "  20BigBusiness: -0.0037\n",
      "  20Conservatives: -0.5624\n",
      "  20Gay: 0.4337\n",
      "  20Congress: -0.0585\n",
      "  20Muslims: 0.1946\n",
      "  20Jews: 0.0180\n",
      "  20Christ: -0.0718\n",
      "  20Police: -0.1582\n",
      "  20Transgender: -0.2229\n",
      "  20Scientist: -0.0820\n",
      "  20Blm: -0.0958\n",
      "  16VoteSum: -1.2912\n",
      "\n",
      "Class '3.0' vs. others:\n",
      "  Intercept: 0.230788765963797\n",
      "  diff_HandleHealth: 0.4090\n",
      "  diff_GunHowMany: 0.4688\n",
      "  diff_HandleImmig: 0.1417\n",
      "  diff_SocMed: 0.1226\n",
      "  diff_Age: 0.0483\n",
      "  diff_Fundamentalist: 0.1819\n",
      "  diff_Feminist: -0.1581\n",
      "  diff_Liberal: -0.2104\n",
      "  diff_Union: -0.0297\n",
      "  diff_BigBusiness: 0.1949\n",
      "  diff_Conservatives: -0.0185\n",
      "  diff_Gay: 0.0369\n",
      "  diff_Congress: -0.0524\n",
      "  diff_Muslims: 0.0362\n",
      "  diff_Jews: 0.1819\n",
      "  diff_Christ: 0.0886\n",
      "  diff_Police: -0.1400\n",
      "  diff_Transgender: -0.1972\n",
      "  diff_Scientist: 0.1140\n",
      "  diff_Blm: -0.0634\n",
      "  20HandleHealth: 0.6088\n",
      "  20GunHowMany: -0.2625\n",
      "  20HandleImmig: 0.0827\n",
      "  20SocMed: 0.0213\n",
      "  20Age: -0.0541\n",
      "  20Fundamentalist: -0.2209\n",
      "  20Feminist: 0.3357\n",
      "  20Liberal: 0.6977\n",
      "  20Union: 0.0769\n",
      "  20BigBusiness: -0.1758\n",
      "  20Conservatives: -0.5191\n",
      "  20Gay: 0.1639\n",
      "  20Congress: -0.2937\n",
      "  20Muslims: -0.0765\n",
      "  20Jews: -0.0531\n",
      "  20Christ: 0.2005\n",
      "  20Police: -0.2329\n",
      "  20Transgender: -0.1247\n",
      "  20Scientist: 0.0860\n",
      "  20Blm: 0.2718\n",
      "  16VoteSum: -0.2652\n",
      "\n",
      "Class '4.0' vs. others:\n",
      "  Intercept: 1.076312688897211\n",
      "  diff_HandleHealth: 0.0424\n",
      "  diff_GunHowMany: -0.0502\n",
      "  diff_HandleImmig: -0.1874\n",
      "  diff_SocMed: -0.1690\n",
      "  diff_Age: -0.1120\n",
      "  diff_Fundamentalist: -0.0280\n",
      "  diff_Feminist: 0.0750\n",
      "  diff_Liberal: 0.0900\n",
      "  diff_Union: 0.0614\n",
      "  diff_BigBusiness: -0.0678\n",
      "  diff_Conservatives: 0.0045\n",
      "  diff_Gay: 0.1533\n",
      "  diff_Congress: -0.0099\n",
      "  diff_Muslims: -0.0912\n",
      "  diff_Jews: 0.0094\n",
      "  diff_Christ: 0.0957\n",
      "  diff_Police: 0.1228\n",
      "  diff_Transgender: -0.1340\n",
      "  diff_Scientist: -0.0512\n",
      "  diff_Blm: 0.1927\n",
      "  20HandleHealth: 0.0549\n",
      "  20GunHowMany: 0.0898\n",
      "  20HandleImmig: 0.1138\n",
      "  20SocMed: 0.1579\n",
      "  20Age: -0.0714\n",
      "  20Fundamentalist: 0.0275\n",
      "  20Feminist: -0.0086\n",
      "  20Liberal: -0.1926\n",
      "  20Union: -0.0046\n",
      "  20BigBusiness: 0.0173\n",
      "  20Conservatives: 0.1600\n",
      "  20Gay: -0.4533\n",
      "  20Congress: -0.2082\n",
      "  20Muslims: 0.1559\n",
      "  20Jews: 0.0175\n",
      "  20Christ: -0.3020\n",
      "  20Police: -0.0095\n",
      "  20Transgender: 0.3805\n",
      "  20Scientist: -0.0367\n",
      "  20Blm: -0.2183\n",
      "  16VoteSum: -0.0377\n",
      "\n",
      "Class '5.0' vs. others:\n",
      "  Intercept: 0.3925381399604562\n",
      "  diff_HandleHealth: -0.3528\n",
      "  diff_GunHowMany: -0.2094\n",
      "  diff_HandleImmig: -0.3573\n",
      "  diff_SocMed: -0.0232\n",
      "  diff_Age: 0.0566\n",
      "  diff_Fundamentalist: 0.0796\n",
      "  diff_Feminist: 0.0736\n",
      "  diff_Liberal: 0.1787\n",
      "  diff_Union: 0.1230\n",
      "  diff_BigBusiness: -0.0643\n",
      "  diff_Conservatives: -0.0555\n",
      "  diff_Gay: -0.1971\n",
      "  diff_Congress: 0.2180\n",
      "  diff_Muslims: 0.0591\n",
      "  diff_Jews: -0.1810\n",
      "  diff_Christ: -0.1611\n",
      "  diff_Police: 0.1052\n",
      "  diff_Transgender: 0.3709\n",
      "  diff_Scientist: 0.0518\n",
      "  diff_Blm: -0.0726\n",
      "  20HandleHealth: -0.2400\n",
      "  20GunHowMany: 0.2592\n",
      "  20HandleImmig: 0.1645\n",
      "  20SocMed: -0.2588\n",
      "  20Age: 0.1007\n",
      "  20Fundamentalist: 0.0224\n",
      "  20Feminist: -0.3036\n",
      "  20Liberal: -0.5478\n",
      "  20Union: -0.0082\n",
      "  20BigBusiness: 0.1997\n",
      "  20Conservatives: 0.7122\n",
      "  20Gay: 0.0188\n",
      "  20Congress: -0.1486\n",
      "  20Muslims: -0.1095\n",
      "  20Jews: 0.1467\n",
      "  20Christ: -0.1084\n",
      "  20Police: -0.1413\n",
      "  20Transgender: -0.1310\n",
      "  20Scientist: -0.1198\n",
      "  20Blm: -0.0973\n",
      "  16VoteSum: 0.5434\n",
      "\n",
      "Class '6.0' vs. others:\n",
      "  Intercept: 0.19228213665912572\n",
      "  diff_HandleHealth: 0.2627\n",
      "  diff_GunHowMany: -0.1335\n",
      "  diff_HandleImmig: -0.4324\n",
      "  diff_SocMed: 0.0771\n",
      "  diff_Age: -0.0194\n",
      "  diff_Fundamentalist: -0.1229\n",
      "  diff_Feminist: 0.0903\n",
      "  diff_Liberal: 0.0363\n",
      "  diff_Union: 0.1952\n",
      "  diff_BigBusiness: 0.0673\n",
      "  diff_Conservatives: 0.0014\n",
      "  diff_Gay: 0.1798\n",
      "  diff_Congress: -0.1137\n",
      "  diff_Muslims: -0.2136\n",
      "  diff_Jews: -0.0215\n",
      "  diff_Christ: -0.0545\n",
      "  diff_Police: -0.1832\n",
      "  diff_Transgender: -0.1960\n",
      "  diff_Scientist: -0.0320\n",
      "  diff_Blm: -0.0103\n",
      "  20HandleHealth: -0.3690\n",
      "  20GunHowMany: 0.0720\n",
      "  20HandleImmig: -0.0603\n",
      "  20SocMed: 0.0092\n",
      "  20Age: -0.0748\n",
      "  20Fundamentalist: -0.0335\n",
      "  20Feminist: -0.2178\n",
      "  20Liberal: -0.3836\n",
      "  20Union: -0.3669\n",
      "  20BigBusiness: -0.0763\n",
      "  20Conservatives: 0.4528\n",
      "  20Gay: -0.3266\n",
      "  20Congress: 0.3057\n",
      "  20Muslims: 0.1875\n",
      "  20Jews: -0.1967\n",
      "  20Christ: -0.0802\n",
      "  20Police: 0.3557\n",
      "  20Transgender: 0.3306\n",
      "  20Scientist: -0.0176\n",
      "  20Blm: -0.1700\n",
      "  16VoteSum: 1.1609\n",
      "\n",
      "Class '7.0' vs. others:\n",
      "  Intercept: -1.7149819909333808\n",
      "  diff_HandleHealth: -0.7975\n",
      "  diff_GunHowMany: -0.3546\n",
      "  diff_HandleImmig: -0.0335\n",
      "  diff_SocMed: 0.0120\n",
      "  diff_Age: 0.0511\n",
      "  diff_Fundamentalist: -0.1385\n",
      "  diff_Feminist: 0.1194\n",
      "  diff_Liberal: -0.0051\n",
      "  diff_Union: 0.2599\n",
      "  diff_BigBusiness: -0.1430\n",
      "  diff_Conservatives: -0.1696\n",
      "  diff_Gay: -0.1584\n",
      "  diff_Congress: 0.0303\n",
      "  diff_Muslims: 0.0116\n",
      "  diff_Jews: -0.1676\n",
      "  diff_Christ: -0.2094\n",
      "  diff_Police: 0.1834\n",
      "  diff_Transgender: 0.2799\n",
      "  diff_Scientist: -0.2137\n",
      "  diff_Blm: -0.0299\n",
      "  20HandleHealth: -0.5535\n",
      "  20GunHowMany: 0.3263\n",
      "  20HandleImmig: -0.3981\n",
      "  20SocMed: -0.1823\n",
      "  20Age: -0.0327\n",
      "  20Fundamentalist: -0.0768\n",
      "  20Feminist: -0.3251\n",
      "  20Liberal: -0.7313\n",
      "  20Union: -0.0582\n",
      "  20BigBusiness: 0.0885\n",
      "  20Conservatives: 0.8330\n",
      "  20Gay: -0.0022\n",
      "  20Congress: 0.3283\n",
      "  20Muslims: -0.2583\n",
      "  20Jews: -0.0136\n",
      "  20Christ: 0.1161\n",
      "  20Police: 0.2884\n",
      "  20Transgender: -0.0070\n",
      "  20Scientist: -0.0027\n",
      "  20Blm: -0.2585\n",
      "  16VoteSum: 2.0995\n",
      "\n",
      "Mean Ordinal Error (0=perfect): 0.81\n",
      "Mean Squared Ordinal Error: 1.81\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "# 1) Read the CSV file\n",
    "\n",
    "# --------------------------------------------------------------\n",
    "# 2) Prepare columns: define your 2020 numeric features + 16VoteSum\n",
    "#    Adjust this list to match your actual numeric 2020 columns\n",
    "# --------------------------------------------------------------\n",
    "twenty_features = ['diff_HandleHealth', 'diff_GunHowMany', 'diff_HandleImmig', 'diff_SocMed', 'diff_Age', 'diff_Fundamentalist', 'diff_Feminist', 'diff_Liberal', 'diff_Union', 'diff_BigBusiness', 'diff_Conservatives', 'diff_Gay', 'diff_Congress', 'diff_Muslims', 'diff_Jews', 'diff_Christ', 'diff_Police', 'diff_Transgender', 'diff_Scientist', 'diff_Blm','20HandleHealth',  '20GunHowMany','20HandleImmig','20SocMed', '20Age',\n",
    "'20Fundamentalist', '20Feminist', '20Liberal',\n",
    "       '20Union', '20BigBusiness', '20Conservatives', '20Gay', '20Congress',\n",
    "       '20Muslims', '20Jews', '20Christ', '20Police', '20Transgender',\n",
    "       '20Scientist', '20Blm']\n",
    "\n",
    "\n",
    "# We'll include 16VoteSum as part of our predictors\n",
    "predictors = twenty_features + [\"16VoteSum\"]\n",
    "\n",
    "# --------------------------------------------------------------\n",
    "# 3) Ensure 16VoteSum and 20VoteSum are numeric\n",
    "# --------------------------------------------------------------\n",
    "mapping_16 = {\n",
    "    \"Strong Democrat\": 1,\n",
    "    \"Not very strong Democrat\": 2,\n",
    "    \"Independent-Democrat\": 3,\n",
    "    \"Independent\": 4,\n",
    "    \"Independent-Republican\": 5,\n",
    "    \"Not very strong Republican\": 6,\n",
    "    \"Strong Republican\": 7\n",
    "}\n",
    "\n",
    "# For 2016\n",
    "df[\"16VoteSum\"] = df[\"16VoteSum\"].map(mapping_16)\n",
    "df[\"20VoteSum\"] = df[\"20VoteSum\"].map(mapping_16)\n",
    "print(df[\"20VoteSum\"])\n",
    "\n",
    "# --------------------------------------------------------------\n",
    "# 4) Drop rows where any needed column is missing\n",
    "# --------------------------------------------------------------\n",
    "df_clean = df.dropna(subset=predictors + [\"20VoteSum\"]).copy()\n",
    "\n",
    "# --------------------------------------------------------------\n",
    "# 5) Create X (predictors) and y (target)\n",
    "# --------------------------------------------------------------\n",
    "X = df_clean[predictors]\n",
    "y = df_clean[\"20VoteSum\"]  # This is multiclass (1..7, for example)\n",
    "\n",
    "# --------------------------------------------------------------\n",
    "# 6) Train/Test Split\n",
    "# --------------------------------------------------------------\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=y  # helps preserve class proportions\n",
    ")\n",
    "\n",
    "# --------------------------------------------------------------\n",
    "# 7) (Optional) Scale numeric features to help with convergence\n",
    "# --------------------------------------------------------------\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled  = scaler.transform(X_test)\n",
    "\n",
    "# --------------------------------------------------------------\n",
    "# 8) Multinomial Logistic Regression\n",
    "#    We'll use solver='lbfgs' which supports multi_class='multinomial'\n",
    "# --------------------------------------------------------------\n",
    "model = LogisticRegression(\n",
    "    multi_class='multinomial',\n",
    "    solver='lbfgs',\n",
    "    penalty='l2',\n",
    "    C=1.0,         # inverse of regularization strength\n",
    "    max_iter=500,  # increase if you see convergence warnings\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# --------------------------------------------------------------\n",
    "# 9) Evaluate Predictions\n",
    "# --------------------------------------------------------------\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "print(\"=== Confusion Matrix ===\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "print(\"\\n=== Classification Report ===\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# --------------------------------------------------------------\n",
    "# 10) Look at Coefficients\n",
    "#     model.coef_ is shape [n_classes, n_features]\n",
    "# --------------------------------------------------------------\n",
    "classes_ = model.classes_  # e.g., array([1,2,3,4,5,6,7]) if those are the labels\n",
    "coefs = model.coef_\n",
    "intercepts = model.intercept_\n",
    "\n",
    "print(\"\\n=== Multinomial Regression Coefficients ===\")\n",
    "for i, cls in enumerate(classes_):\n",
    "    print(f\"\\nClass '{cls}' vs. others:\")\n",
    "    print(\"  Intercept:\", intercepts[i])\n",
    "    for j, col in enumerate(predictors):\n",
    "        print(f\"  {col}: {coefs[i][j]:.4f}\")\n",
    "\n",
    "# --------------------------------------------------------------\n",
    "# 11) (Optional) Calculate an Ordinal Metric\n",
    "#     e.g., the average absolute difference |y_pred - y_true|\n",
    "# --------------------------------------------------------------\n",
    "def mean_ordinal_error(y_true, y_pred):\n",
    "    # Both are numeric arrays (e.g., 1..7)\n",
    "    return np.mean(np.abs(y_true - y_pred))\n",
    "\n",
    "moe = mean_ordinal_error(y_test, y_pred)\n",
    "print(f\"\\nMean Ordinal Error (0=perfect): {moe:.2f}\")\n",
    "\n",
    "# Another approach: Weighted MSE\n",
    "def mean_squared_ordinal_error(y_true, y_pred):\n",
    "    return np.mean((y_true - y_pred)**2)\n",
    "\n",
    "mse = mean_squared_ordinal_error(y_test, y_pred)\n",
    "print(f\"Mean Squared Ordinal Error: {mse:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9135844e-43e6-498b-be40-75231117d0c5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
